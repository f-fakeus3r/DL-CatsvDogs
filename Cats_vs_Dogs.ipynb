{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural Convolucional\n",
    "## Reconhecimento e distinção de imagens de gatos e cachorros\n",
    "### Este notebook traz a elaboração de uma rede neural convolucional com camadas Convolucionais, Pooling e Fully Connected. A máquina recebe instruções de Deep Learning, com treinamento, para reconhecimento e distinção de imagens de cachorros e gatos.\n",
    "### Ao fim, o modelo é salvo em um banco de dados do MongoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependências (já instaladas)\n",
    "#!pip install pymongo\n",
    "#!pip install opencv-python\n",
    "#!pip install tflearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definições e criação da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #Trabalhar com imagens (converte imagens em Array)\n",
    "import numpy as np \n",
    "import os #Trabalhar com gerenciamento de arquivos\n",
    "from random import shuffle \n",
    "from tqdm import tqdm #Barrinha de carregamento\n",
    "from pymongo import MongoClient\n",
    "\n",
    "TRAIN_DIR = 'dataset/train'\n",
    "TEST_DIR = 'dataset/test'\n",
    "\n",
    "IMG_SIZE = 50\n",
    "\n",
    "LR = 1e-3 #Learning Rate: 0.001 (1∗10−3=1∗1103=1∗11000 = 0.001) \n",
    "\n",
    "MODEL_NAME = 'dogsvscats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_img(img):\n",
    "    word_label = img.split('.')[-3] #Pegando o prefixo do nome da imagem\n",
    "    if word_label == 'cat':\n",
    "        return [1,0] #Label 1,0 = \"Completamente\" gato\n",
    "    else:\n",
    "        return [0,1] #Label 0,1 = \"Completamente\" cachorro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        label = label_img(img)#Dando [1,0] ou [0,1] para as imagens\n",
    "        path = os.path.join(TRAIN_DIR, img) #Caminho completo da imagem\n",
    "        img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE)) #Resize de 50x50, deixando em escala de cinza\n",
    "        training_data.append([np.array(img), np.array(label)]) #Salva em lista, formato Numpy Array\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data) #Salva dados\n",
    "    return training_data        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(TEST_DIR)):\n",
    "            path= os.path.join(TEST_DIR, img)\n",
    "            img_num = img.split('.')[0] #Renomea os arquivos para deixar apenas os números\n",
    "            img = cv2.resize(cv2.imread(path, cv2.IMREAD_GRAYSCALE), (IMG_SIZE, IMG_SIZE), cv2.INTER_AREA)#Resize de 50x50, deixando em escala de cinza\n",
    "            testing_data.append([np.array(img), img_num]) #Salvando em lista, formato Numpy Array\n",
    "        \n",
    "    np.save('test_data.npy', testing_data) #Salva dados\n",
    "    return testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = create_train_data() #Chamada da função para criação do set de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criação/Organização da Rede Neural\n",
    "#Rede neural de 8 neurônios convolucionais\n",
    "import tensorflow\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 2, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 2)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 2, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet, tensorboard_dir='log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treino do modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso já exista modelo na pasta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carregamento do modelo, caso já exista\n",
    "if os.path.exists('dogsvscats.meta'):\n",
    "    model.load('dogsvscats')\n",
    "else:\n",
    "    print('Arquivos do modelo inexistente')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caso não: Treinar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data[:-500]\n",
    "test = train_data[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train], dtype=np.float32).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "Y = [i[1] for i in train]\n",
    "\n",
    "test_x = np.array([i[0] for i in test], dtype=np.float32).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "test_y = [i[1] for i in test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Celula que efetivamente treina o modelo\n",
    "model.fit({'input': X}, {'targets': Y}, n_epoch=11, validation_set=({'input': test_x}, {'targets': test_y}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)   #Treinando a rede Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(MODEL_NAME) #Salva o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output: Gerando tabela de imagens com rótulo Cat ou Dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "test_data = process_test_data()\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "for num, data in enumerate(test_data[21:41]): #20 dados da lista\n",
    "    img_num = data[1] #Tag da imagem/Nome do arquivo\n",
    "    img_data = data[0] #Imagem em si\n",
    "    \n",
    "    y = fig.add_subplot(4, 5, num+1)\n",
    "    orig = img_data\n",
    "    data = img_data.reshape(IMG_SIZE, IMG_SIZE, 1)\n",
    "    \n",
    "    model_out = model.predict([data])[0]\n",
    "    \n",
    "    if np.argmax(model_out) == 1:\n",
    "        str_label = \"Dog\"\n",
    "    else:\n",
    "        str_label = \"Cat\"\n",
    "    \n",
    "    y.imshow(cv2.cvtColor(orig, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(str_label)\n",
    "    y.axes.get_xaxis().set_visible(False)\n",
    "    y.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexão com MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bson.binary import Binary\n",
    "from bson import ObjectId\n",
    "import pymongo, gridfs\n",
    "from gridfs import GridFS\n",
    "from pymongo import MongoClient\n",
    "\n",
    "\n",
    "myclient = pymongo.MongoClient('mongodb://leonardolino:91525437@cluster0-shard-00-00.bbr4t.mongodb.net:27017,cluster0-shard-00-01.bbr4t.mongodb.net:27017,cluster0-shard-00-02.bbr4t.mongodb.net:27017/sprint3-pb-compass?ssl=true&replicaSet=atlas-qgdhlr-shard-0&authSource=admin&retryWrites=true&w=majority')\n",
    "mydb = myclient['sprint3-pb-compass']\n",
    "mycol = mydb['modelo']\n",
    "\n",
    "# Salvando os arquivos meta, index, data e checkpoint no DB\n",
    "# São necessários estes três arquivos para funcionar corretamente\n",
    "with open(\"dogsvscats.meta\", \"rb\") as f:\n",
    "    encoded = Binary(f.read())\n",
    "mycol.insert_one({\"filename\": \"dogsvscats.meta\", \"file\": encoded, \"description\": \"Keras model\" })\n",
    "\n",
    "with open(\"checkpoint\", \"rb\") as f:\n",
    "    encoded = Binary(f.read())\n",
    "mycol.insert_one({\"filename\": \"checkpoint\", \"file\": encoded, \"description\": \"Keras model\" })\n",
    "\n",
    "with open(\"dogsvscats.data-00000-of-00001\", \"rb\") as f:\n",
    "    encoded = Binary(f.read())\n",
    "mycol.insert_one({\"filename\": \"dogsvscats.data-00000-of-00001\", \"file\": encoded, \"description\": \"Keras model\" })\n",
    "\n",
    "with open(\"dogsvscats.index\", \"rb\") as f:\n",
    "    encoded = Binary(f.read())\n",
    "mycol.insert_one({\"filename\": \"dogsvscats.index\", \"file\": encoded, \"description\": \"Keras model\" })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trazendo de volta do DB\n",
    "data1 = mycol.find_one({'filename': 'dogsvscats.meta'})\n",
    "with open(\"dogsvscats.meta\", \"wb\") as f:\n",
    "    f.write(data1['file'])\n",
    "    \n",
    "data2 = mycol.find_one({'filename': 'checkpoint'})\n",
    "with open(\"checkpoint\", \"wb\") as f:\n",
    "    f.write(data2['file'])\n",
    "    \n",
    "data3 = mycol.find_one({'filename': 'dogsvscats.data-00000-of-00001'})\n",
    "with open(\"dogsvscats.data-00000-of-00001\", \"wb\") as f:\n",
    "    f.write(data3['file'])\n",
    "    \n",
    "data4 = mycol.find_one({'filename': 'dogsvscats.index'})\n",
    "with open(\"dogsvscats.index\", \"wb\") as f:\n",
    "    f.write(data4['file'])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
